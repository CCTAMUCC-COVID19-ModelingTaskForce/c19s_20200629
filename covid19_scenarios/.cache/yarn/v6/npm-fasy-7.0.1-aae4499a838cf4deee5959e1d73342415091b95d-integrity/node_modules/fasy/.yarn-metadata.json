{
  "manifest": {
    "name": "fasy",
    "version": "7.0.1",
    "description": "FP iterator helpers that are async/generator aware",
    "main": "./dist/fasy.js",
    "scripts": {
      "test": "node scripts/node-tests.js",
      "test:dist": "TEST_DIST=true npm test",
      "test:package": "TEST_PACKAGE=true npm test",
      "test:all": "npm test && npm run test:dist && npm run test:package",
      "coverage": "istanbul cover scripts/node-tests.js",
      "coverage:report": "npm run coverage && cat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.js",
      "build-core": "node scripts/build-core.js",
      "build": "npm run build-core",
      "prepare": "npm run build",
      "prepublish": "npm run build && npm run test:all",
      "publish": "npm run coverage:report"
    },
    "devDependencies": {
      "coveralls": "~3.0.0",
      "qunit": "~2.9.1",
      "terser": "~4.0.0"
    },
    "repository": {
      "type": "git",
      "url": "https://github.com/getify/fasy.git"
    },
    "keywords": [
      "fp",
      "functional programming",
      "async"
    ],
    "bugs": {
      "url": "https://github.com/getify/fasy/issues",
      "email": "getify@gmail.com"
    },
    "homepage": "https://github.com/getify/fasy",
    "author": {
      "name": "Kyle Simpson",
      "email": "getify@gmail.com"
    },
    "license": "MIT",
    "_registry": "npm",
    "_loc": "/home/ekrell/Documents/Work/repos/COVID19/c19s_20200629/covid19_scenarios/.cache/yarn/v6/npm-fasy-7.0.1-aae4499a838cf4deee5959e1d73342415091b95d-integrity/node_modules/fasy/package.json",
    "readmeFilename": "README.md",
    "readme": "# fasy\n\n[![Build Status](https://travis-ci.org/getify/fasy.svg?branch=master)](https://travis-ci.org/getify/fasy)\n[![npm Module](https://badge.fury.io/js/fasy.svg)](https://www.npmjs.org/package/fasy)\n[![Dependencies](https://david-dm.org/getify/fasy.svg)](https://david-dm.org/getify/fasy)\n[![devDependencies](https://david-dm.org/getify/fasy/dev-status.svg)](https://david-dm.org/getify/fasy?type=dev)\n[![Coverage Status](https://coveralls.io/repos/github/getify/fasy/badge.svg?branch=master)](https://coveralls.io/github/getify/fasy?branch=master)\n\n**fasy** (/ˈfāsē/) is a utility library of FP array iteration helpers (like `map(..)`, `filter(..)`, etc), as well as function composition and transducing.\n\nWhat's different from other FP libraries is that its methods are capable of operating asynchronously, via `async function` functions and/or `function*` generators. **fasy** supports both concurrent and serial asynchrony.\n\nFor concurrent asynchrony, **fasy** also supports limiting the batch size to avoid overloading resources.\n\n## Environment Support\n\nThis library uses ES2017 (and ES6) features. If you need to support environments prior to ES2017, transpile it first (with Babel, etc).\n\n## At A Glance\n\nHere's a quick example:\n\n```js\nvar users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\nFA.concurrent.map( getOrders, users )\n.then( userOrders => console.log( userOrders ) );\n```\n\nThis would work fine with any implementation of `map(..)` if `getOrders(..)` was synchronous. But `concurrent.map(..)` is different in that it handles/expects asynchronously completing functions, like `async function` functions or `function*` generators. Of course, you can *also* use normal synchronous functions as well.\n\n`concurrent.map(..)` will run each call to `getOrders(..)` concurrently (aka \"in parallel\"), and once all are complete, fulfill its returned promise with the final result of the mapping.\n\nBut what if you wanted to run each `getOrders(..)` call one at a time, in succession? Use `serial.map(..)`:\n\n```js\nvar users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\nFA.serial.map( getOrders, users )\n.then( userOrders => console.log( userOrders ) );\n```\n\nAs with `concurrent.map(..)`, once all mappings are complete, the returned promise is fulfilled with the final result of the mapping.\n\n**fasy** handles `function*` generators via its own [generator-runner](https://github.com/getify/You-Dont-Know-JS/blob/master/async%20%26%20performance/ch4.md#promise-aware-generator-runner), similar to utilities provided by various async libraries (e.g., [`asynquence#runner(..)`](https://github.com/getify/asynquence/tree/master/contrib#runner-plugin), [`Q.spawn(..)`](https://github.com/kriskowal/q/wiki/API-Reference#qspawngeneratorfunction)).:\n\n```js\nvar users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\nFA.serial.map(\n    function *getOrders(username){\n        var user = yield lookupUser( username );\n        return lookupOrders( user.id );\n    },\n    users\n)\n.then( userOrders => console.log( userOrders ) );\n```\n\n## Background/Motivation\n\nFunctional helpers like `map(..)` / `filter(..)` / `reduce(..)` are quite handy for iterating through a list of operations:\n\n```js\n[1,2,3,4,5].filter(v => v % 2 == 0);\n// [2,4]\n```\n\nThe [sync-async pattern](https://github.com/getify/You-Dont-Know-JS/blob/master/async%20%26%20performance/ch4.md#generators--promises) of `async function` functions offers much more readable asynchronous flow control code:\n\n```js\nasync function getOrders(username) {\n    var user = await lookupUser( username );\n    return lookupOrders( user.id );\n}\n\ngetOrders( \"getify\" )\n.then( orders => console.log( orders ) );\n```\n\nAlternately, you could use a `function*` generator along with a [generator-runner](https://github.com/getify/You-Dont-Know-JS/blob/master/async%20%26%20performance/ch4.md#promise-aware-generator-runner) (named `run(..)` in the below snippet):\n\n```js\nrun( function *getOrders(username){\n    var user = yield lookupUser( username );\n    return lookupOrders( user.id );\n}, \"getify\" )\n.then( orders => console.log( orders ) );\n```\n\nThe problem is, mixing FP-style iteration like `map(..)` with `async function` functions / `function*` generators doesn't quite work:\n\n```js\n// BROKEN CODE -- DON'T COPY!!\n\nasync function getAllOrders() {\n    var users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\n    var userOrders = users.map( function getOrders(username){\n        // `await` won't work here inside this inner function\n        var user = await lookupUser( username );\n        return lookupOrders( user.id );\n    } );\n\n    // everything is messed up now, since `map(..)` works synchronously\n    console.log( userOrders );\n}\n```\n\nThe `await` isn't valid inside the inner function `getOrders(..)` since that's a normal function, not an `async function` function. Also, `map(..)` here is the standard array method that operates synchronously, so it doesn't wait for all the lookups to finish.\n\nIf it's OK to run the `getOrders(..)` calls concurrently -- in this particular example, it quite possibly is -- then you could use `Promise.all(..)` along with an inner `async function` function:\n\n```js\nasync function getAllOrders() {\n    var users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\n    var userOrders = await Promise.all( users.map( async function getOrders(username){\n        var user = await lookupUser( username );\n        return lookupOrders( user.id );\n    } ) );\n\n    // this works\n    console.log( userOrders );\n}\n```\n\nUnfortunately, aside from being more verbose, this \"fix\" is fairly limited. It really only works for `map(..)` and not for something like `filter(..)`. Also, as that fix assumes concurrency, there's no good way to do the FP-style iterations serially.\n\n## Overview\n\nWith **fasy**, you can do either concurrent or serial iterations of asynchronous operations.\n\n### Concurrent Asynchrony\n\nFor example, consider this [`concurrent.map(..)`](docs/concurrent-API.md#concurrentmap) operation:\n\n```js\nasync function getAllOrders() {\n    var users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\n    var userOrders = await FA.concurrent.map(\n        async function getOrders(username){\n            var user = await lookupUser( username );\n            return lookupOrders( user.id );\n        },\n        users\n    );\n\n    console.log( userOrders );\n}\n```\n\nNow let's look at the same task, but with a [`serial.map(..)`](docs/serial-API.md#serialmap) operation:\n\n```js\nasync function getAllOrders() {\n    var users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\n    var userOrders = await FA.serial.map(\n        async function getOrders(username){\n            var user = await lookupUser( username );\n            return lookupOrders( user.id );\n        },\n        users\n    );\n\n    console.log( userOrders );\n}\n```\n\nLet's look at a `filter(..)` example:\n\n```js\nasync function getActiveUsers() {\n    var users = [ \"bzmau\", \"getify\", \"frankz\" ];\n\n    return FA.concurrent.filter(\n        async function userIsActive(username){\n            var user = await lookupUser( username );\n            return user.isActive;\n        },\n        users\n    );\n}\n```\n\nThe equivalent of this would be much more verbose/awkward than just a simple `Promise.all(..)` \"fix\" as described earlier. And of course, you can also use [`serial.filter(..)`](docs/serial-API.md#serialfilter) to process the operations serially if necessary.\n\n#### Limiting Concurrency\n\nTo limit the concurrency (aka, parallelism) of your operations, there are two modes to select from: *continuous pooling* (default) and *batch*.\n\n**Note:** Such limitations on concurrency are often useful when the operations involve finite system resources, like OS file handles or network connection ports, and as such you want to avoid exhausting those resources and creating errors or over-burdening the system.\n\nTo illustrate, *continuous pooling* mode:\n\n```js\nasync function getAllURLs(urls) {\n    var responses = await FA.concurrent(5).map(fetch,urls);\n\n    // .. render responses\n}\n```\n\nIn this example, the `(5)` part of `FA.concurrent(5)` limits the concurrency to only (up to) five active `fetch(..)` calls at any given moment. As soon as one finishes, if there are any more calls waiting, the next one is activated. This argument must be greater than zero.\n\nThe `concurrent(5)` call is actually a shorthand for `concurrent(5,5)`, which includes a second argument: minimum active threshold. In other words, the way *continuous pooling* mode works is, the first five `fetch(..)` calls are activated, and when the first one finishes, the active count is now down to `4`, which is below that specified `5` threshold, so the next one (if any are waiting) is activated.\n\nIn contrast to *continuous pooling* mode, *batch* mode is activated by explicitly specifying a number for this second argument that is lower than the first argument (but still greater than zero).\n\nFor example, `concurrent(5,1)` runs a batch of five concurrent `fetch(..)` calls, but doesn't start the next batch of calls until the active count falls below `1` (aka, the whole batch finishes):\n\n```js\nasync function getAllURLs(urls) {\n    var responses = await FA.concurrent(5,1).map(fetch,urls);\n\n    // .. render responses\n}\n```\n\nAnd `concurrent(5,3)` would run a batch of five active calls, then refill the active batch set (to five) once the active count gets below `3`.\n\nWith these two limit arguments, you have complete control to fine tune how much concurrent activity is appropriate.\n\nYou can safely call `concurrent(..)` multiple times with the same arguments -- the resulting concurrency-limited API is internally cached -- or with any different arguments, as necessary. You can also store the concurrency-limited API object and re-use it, if you prefer:\n\n```js\nFA.concurrent(5).map(..);\nFA.concurrent(5).filter(..);\nFA.concurrent(12).forEach(..);\n\nvar FAc5 = FA.concurrent(5);\nFAc5.map(..);\nFAc5.filter(..);\n```\n\n### Serial Asynchrony\n\nSome operations are naturally serial. For example, `reduce(..)` wouldn't make any sense processing as concurrent operations; it naturally runs left-to-right through the list. As such, `concurrent.reduce(..)` / `concurrent.reduceRight(..)` delegate respectively to `serial.reduce(..)` / `serial.reduceRight(..)`.\n\nFor example, consider modeling an asynchronous function composition as a serial `reduce(..)`:\n\n```js\n// `prop(..)` is a standard curried FP helper for extracting a property from an object\nvar prop = p => o => o[p];\n\n// ***************************\n\nasync function getOrders(username) {\n    return FA.serial.reduce(\n        async (ret,fn) => fn( ret ),\n        username,\n        [ lookupUser, prop( \"id\" ), lookupOrders ]\n    );\n}\n\ngetOrders( \"getify\" )\n.then( orders => console.log( orders ) );\n```\n\n**Note:** In this composition, the second call (from `prop(\"id\")` -- a standard FP helper) is **synchronous**, while the first and third calls are **asynchronous**. That's OK, because promises automatically lift non-promise values. [More on that](#syncasync-normalization) below.\n\nThe async composition being shown here is only for illustration purposes. **fasy** provides [`serial.compose(..)`](docs/serial-API.md#serialcompose) and [`serial.pipe(..)`](docs/serial-API.md#serialpipe) for performing async compositions ([see below](#async-composition)); these methods should be preferred over doing it manually yourself.\n\nBy the way, instead of `async (ret,fn) => fn(ret)` as the reducer, you can provide a `function*` generator and it works the same:\n\n```js\nasync function getOrders(username) {\n    return FA.serial.reduce(\n        function *composer(ret,fn) { return fn( ret ); },\n        username,\n        [ lookupUser, prop( \"id\" ), lookupOrders ]\n    );\n}\n\ngetOrders( \"getify\" )\n.then( orders => console.log( orders ) );\n```\n\nSpecifying the reducer as an `async function` function or a `function*` generator gives you the flexibility to do inner `await` / `yield` flow control as necessary.\n\n### Sync/Async Normalization\n\nIn this specific running example, there's no inner asynchronous flow control necessary in the reducer, so it can actually just be a regular function:\n\n```js\nasync function getOrders(username) {\n    return FA.serial.reduce(\n        (ret,fn) => fn( ret ),\n        username,\n        [ lookupUser, prop( \"id\" ), lookupOrders ]\n    );\n}\n\ngetOrders( \"getify\" )\n.then( orders => console.log( orders ) );\n```\n\nThere's an important principle illustrated here that many developers don't realize.\n\nA regular function that returns a promise has the same external behavioral interface as an `async function` function. From the external perspective, when you call a function and get back a promise, it doesn't matter if the function manually created and returned that promise, or whether that promise came automatically from the `async function` invocation. In both cases, you get back a promise, and you wait on it before moving on. The *interface* is the same.\n\nIn the first step of this example's reduction, the `fn(ret)` call is effectively `lookupUser(username)`, which is returning a promise. What's different between `serial.reduce(..)` and a standard synchronous implementation of `reduce(..)` as provided by various other FP libraries, is that if `serial.reduce(..)` receives back a promise from a reducer call, it pauses to wait for that promise to resolve.\n\nBut what about the second step of the reduction, where `fn(ret)` is effectively `prop(\"id\")(user)`? The return from *that* call is an immediate value (the user's ID), not a promise (future value).\n\n**fasy** uses promises internally to normalize both immediate and future values, so the iteration behavior is consistent regardless.\n\n### Async Composition\n\nIn addition to traditional iterations like `map(..)` and `filter(..)`, **fasy** also supports serial-async composition, which is really just a serial-async reduction under the covers.\n\nConsider:\n\n```js\nasync function getFileContents(filename) {\n    var fileHandle = await fileOpen( filename );\n    return fileRead( fileHandle );\n}\n```\n\nThat is fine, but it can also be recognized as an async composition. We can use [`serial.pipe(..)`](docs/serial-API.md#serialpipe) to define it in point-free style:\n\n```js\nvar getFileContents = FA.serial.pipe( [\n    fileOpen,\n    fileRead\n] );\n```\n\nFP libraries traditionally provide synchronous composition with `pipe(..)` and `compose(..)` (sometimes referred to by other names, like `flow(..)` and `flowRight(..)`, respectively). But asynchronous composition can be quite helpful!\n\n### Async Transducing\n\nTransducing is another flavor of FP iteration; it's a combination of composition and list/data-structure reduction. Multiple `map(..)` and `filter(..)` calls can be composed by transforming them as reducers. Again, many FP libraries support traditional synchronous transducing, but since **fasy** has serial-async reduction, you can do serial-async transducing as well!\n\nConsider:\n\n```js\nasync function getFileContents(filename) {\n    var exists = await fileExists( filename );\n    if (exists) {\n        var fileHandle = await fileOpen( filename );\n        return fileRead( fileHandle );\n    }\n}\n```\n\nWe could instead model these operations FP-style as a `filter(..)` followed by two `map(..)`s:\n\n```js\nasync function getFileContents(filename) {\n    return FA.serial.map(\n        fileRead,\n        FA.serial.map(\n            fileOpen,\n            FA.serial.filter(\n                fileExists,\n                [ filename ]\n            )\n        )\n    );\n}\n```\n\nNot only is this a bit more verbose, but if we later wanted to be able to get/combine contents from many files, we'd be iterating over a list three times (once each for the `filter(..)` and two `map(..)` calls). That extra iteration is not just a penalty in terms of more CPU cycles, but it also creates an intermediate array in between each step, which is then thrown away, so memory churn becomes a concern.\n\nThis is where transducing shines! If we transform the `filter(..)` and `map(..)` calls into a composition-compatible form (reducers), we can then combine them into one reducer; that means we can do all the steps at once! So, we'll only have to iterate through the list once, and we won't need to create and throw away any intermediate arrays.\n\nWhile this obviously can work for any number of values in a list, we'll keep our running example simple and just process one file:\n\n```js\nasync function getFileContents(filename) {\n    var transducer = FA.serial.compose( [\n        FA.transducers.filter( fileExists ),\n        FA.transducers.map( fileOpen ),\n        FA.transducers.map( fileRead )\n    ] );\n\n    return FA.transducers.into(\n        transducer,\n        \"\", // empty string as initial value\n        [ filename ]\n    );\n}\n```\n\n**Note:** For simplicity, we used the [`transducers.into(..)`](docs/transducers-API.md#transducersinto) convenience method, but the same task could also have used the more general [`transducers.transduce(..)`](docs/transducers-API.md#transducerstransduce) method.\n\n## API Documentation\n\n* See [Concurrent API](docs/concurrent-API.md) for documentation on the methods in the `FA.concurrent.*` namespace.\n* See [Serial API](docs/serial-API.md) for documenation on the methods in the `FA.serial.*` namespace.\n* See [Transducers API](docs/transducers-API.md) for documentation on the methods in the `FA.transducers.*` namespace.\n\n## Builds\n\n[![Build Status](https://travis-ci.org/getify/fasy.svg?branch=master)](https://travis-ci.org/getify/fasy)\n[![npm Module](https://badge.fury.io/js/fasy.svg)](https://www.npmjs.org/package/fasy)\n\nThe distribution library file (`dist/fasy.js`) comes pre-built with the npm package distribution, so you shouldn't need to rebuild it under normal circumstances.\n\nHowever, if you download this repository via Git:\n\n1. The included build utility (`scripts/build-core.js`) builds (and minifies) `dist/fasy.js` from source. **The build utility expects Node.js version 6+.**\n\n2. To install the build and test dependencies, run `npm install` from the project root directory.\n\n    - **Note:** This `npm install` has the effect of running the build for you, so no further action should be needed on your part.\n\n4. To manually run the build utility with npm:\n\n    ```\n    npm run build\n    ```\n\n5. To run the build utility directly without npm:\n\n    ```\n    node scripts/build-core.js\n    ```\n\n## Tests\n\nA comprehensive test suite is included in this repository, as well as the npm package distribution. The default test behavior runs the test suite using `src/fasy.src.js`.\n\n1. You can run the tests in a browser by opening up `tests/index.html` (**requires ES6+ browser environment**).\n\n2. The included Node.js test utility (`scripts/node-tests.js`) runs the test suite. **This test utility expects Node.js version 6+.**\n\n3. Ensure the test dependencies are installed by running `npm install` from the project root directory.\n\n    - **Note:** Starting with npm v5, the test utility is **not** run automatically during this `npm install`. With npm v4, the test utility automatically runs at this point.\n\n4. To run the test utility with npm:\n\n    ```\n    npm test\n    ```\n\n    Other npm test scripts:\n\n    * `npm run test:dist` will run the test suite against `dist/fasy.js` instead of the default of `src/fasy.src.js`.\n\n    * `npm run test:package` will run the test suite as if the package had just been installed via npm. This ensures `package.json`:`main` properly references `dist/fasy.js` for inclusion.\n\n    * `npm run test:all` will run all three modes of the test suite.\n\n5. To run the test utility directly without npm:\n\n    ```\n    node scripts/node-tests.js\n    ```\n\n### Test Coverage\n\n[![Coverage Status](https://coveralls.io/repos/github/getify/fasy/badge.svg?branch=master)](https://coveralls.io/github/getify/fasy?branch=master)\n\nIf you have [Istanbul](https://github.com/gotwarlost/istanbul) already installed on your system (requires v1.0+), you can use it to check the test coverage:\n\n```\nnpm run coverage\n```\n\nThen open up `coverage/lcov-report/index.html` in a browser to view the report.\n\nTo run Istanbul directly without npm:\n\n```\nistanbul cover scripts/node-tests.js\n```\n\n**Note:** The npm script `coverage:report` is only intended for use by project maintainers. It sends coverage reports to [Coveralls](https://coveralls.io/).\n\n## License\n\nAll code and documentation are (c) 2019 Kyle Simpson and released under the [MIT License](http://getify.mit-license.org/). A copy of the MIT License [is also included](LICENSE.txt).\n",
    "licenseText": "Copyright (c) 2017 Kyle Simpson <getify@gmail.com>\n\nPermission is hereby granted, free of charge, to any person\nobtaining a copy of this software and associated documentation\nfiles (the \"Software\"), to deal in the Software without\nrestriction, including without limitation the rights to use,\ncopy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following\nconditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\nOF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\nWHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/fasy/-/fasy-7.0.1.tgz#aae4499a838cf4deee5959e1d73342415091b95d",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/fasy/-/fasy-7.0.1.tgz",
    "hash": "aae4499a838cf4deee5959e1d73342415091b95d",
    "integrity": "sha512-sFL4XuiCszHTQ/g4EbPiICH0KdxP8zd6N2h4weU4fPUzOErtn5i1wkQLZu2oLqIBkAdvroWpch47/fgtDTffJg==",
    "registry": "npm",
    "packageName": "fasy",
    "cacheIntegrity": "sha512-sFL4XuiCszHTQ/g4EbPiICH0KdxP8zd6N2h4weU4fPUzOErtn5i1wkQLZu2oLqIBkAdvroWpch47/fgtDTffJg== sha1-quRJmoOM9N7uWVnh1zNCQVCRuV0="
  },
  "registry": "npm",
  "hash": "aae4499a838cf4deee5959e1d73342415091b95d"
}